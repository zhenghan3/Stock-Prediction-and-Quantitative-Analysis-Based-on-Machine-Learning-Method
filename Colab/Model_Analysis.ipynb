{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model_Analysis.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOGvYLILy63SSnzHAQcBsqd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"u7-Dz3ncoSWE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599036961116,"user_tz":-480,"elapsed":264170,"user":{"displayName":"A shur","photoUrl":"","userId":"10655620916047482037"}},"outputId":"bfa76bef-78ef-4ca2-de7a-bc5a9971837c"},"source":["# Load the database from google drive\n","import zipfile\n","from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive/')\n","\n","# Unzip the database from google drive to Colab\n","if not os.path.exists('/content/Database'):\n","    zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Colab Notebooks/Dissertation/Factor/Database.zip\", 'r')\n","    zip_ref.extractall(\"/content/Database\")\n","    zip_ref.close()\n","\n","zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Colab Notebooks/Dissertation/Factor/Py.zip\", 'r')\n","zip_ref.extractall(\"/content\")\n","zip_ref.close()\n","\n","if not os.path.exists('/content/Database/result'):\n","    os.makedirs('/content/Database/result')\n","\n","!pip install tushare\n","!pip install jqdatasdk\n","\n","# From Google drive to Colab\n","!cp -rfn \"/content/drive/My Drive/Colab Notebooks/Dissertation/Factor/Database/dataset\" '/content/Database'\n","!cp -rfn \"/content/drive/My Drive/Colab Notebooks/Dissertation/Factor/Database/result/model\" '/content/Database/result'\n","!cp -rfn \"/content/drive/My Drive/Colab Notebooks/Dissertation/Factor/Database/result/acc.pkl\" '/content/Database/result'\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n","Collecting tushare\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/96/d99c405aa2490205c08b3f75335014cde4b4bc4637d637c1dd8b64d6be64/tushare-1.2.60-py3-none-any.whl (214kB)\n","\u001b[K     |████████████████████████████████| 215kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: bs4>=0.0.1 in /usr/local/lib/python3.6/dist-packages (from tushare) (0.0.1)\n","Collecting websocket-client>=0.57.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 8.8MB/s \n","\u001b[?25hCollecting simplejson>=3.16.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/96/1e6b19045375890068d7342cbe280dd64ae73fd90b9735b5efb8d1e044a1/simplejson-3.17.2-cp36-cp36m-manylinux2010_x86_64.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 11.9MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tushare) (2.23.0)\n","Requirement already satisfied: lxml>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tushare) (4.2.6)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4>=0.0.1->tushare) (4.6.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.57.0->tushare) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->tushare) (2.10)\n","Installing collected packages: websocket-client, simplejson, tushare\n","Successfully installed simplejson-3.17.2 tushare-1.2.60 websocket-client-0.57.0\n","Collecting jqdatasdk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/a1/bde42d53633ad9ed5ddb1fbf5b482200ceb4eaa8087dbba63420a3137c29/jqdatasdk-1.8.1-py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 1.9MB/s \n","\u001b[?25hCollecting pandas<=0.25.3,>=0.16.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n","\u001b[K     |████████████████████████████████| 10.4MB 6.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jqdatasdk) (2.23.0)\n","Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from jqdatasdk) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jqdatasdk) (1.15.0)\n","Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.6/dist-packages (from jqdatasdk) (1.3.19)\n","Requirement already satisfied: msgpack>=0.4.7 in /usr/local/lib/python3.6/dist-packages (from jqdatasdk) (1.0.0)\n","Collecting pymysql>=0.7.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/57/af502e0e113f139b3f3add4f1efba899a730a365d2264d476e85b9591da5/PyMySQL-0.10.0-py2.py3-none-any.whl (47kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n","\u001b[?25hCollecting thriftpy2>=0.3.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/f0/9bf08e6b5983aa6a6103818da21eadfaea1ad99ec9882be3e75a30e8e9ff/thriftpy2-0.4.11.tar.gz (498kB)\n","\u001b[K     |████████████████████████████████| 501kB 41.5MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas<=0.25.3,>=0.16.2->jqdatasdk) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas<=0.25.3,>=0.16.2->jqdatasdk) (2018.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jqdatasdk) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jqdatasdk) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jqdatasdk) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jqdatasdk) (3.0.4)\n","Collecting ply<4.0,>=3.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n","\u001b[?25hBuilding wheels for collected packages: thriftpy2\n","  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for thriftpy2: filename=thriftpy2-0.4.11-cp36-cp36m-linux_x86_64.whl size=930463 sha256=5efd61962e085d5504a46b5720b73cffa6f8d51461a6845188d11b5f206ee4e3\n","  Stored in directory: /root/.cache/pip/wheels/58/ae/4c/216f0f9a8a65dcb81e633b70a77740a879e3e923a523eeb315\n","Successfully built thriftpy2\n","\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n","Installing collected packages: pandas, pymysql, ply, thriftpy2, jqdatasdk\n","  Found existing installation: pandas 1.0.5\n","    Uninstalling pandas-1.0.5:\n","      Successfully uninstalled pandas-1.0.5\n","Successfully installed jqdatasdk-1.8.1 pandas-0.25.3 ply-3.11 pymysql-0.10.0 thriftpy2-0.4.11\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pandas"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["cp: cannot stat '/content/drive/My Drive/Colab Notebooks/Dissertation/Factor/Database/result/acc_cv.pkl': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mFYhv24W6TDq","colab_type":"code","colab":{}},"source":["if not os.path.exists(\"/content/drive/My Drive/Colab Notebooks/Dissertation/Factor/Database/dataset\"):\n","    os.makedirs(\"/content/drive/My Drive/Colab Notebooks/Dissertation/Factor/Database/dataset\")\n","\n","# From Colab to Google drive\n","!cp -rfn '/content/Database/result' \"/content/drive/My Drive/Colab Notebooks/Dissertation/Factor/Database\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cR9z9ofcmP-X","colab_type":"code","colab":{}},"source":["# Model analysis\n","    # Plot model accuracy figure by date\n","    # Retrieve monthly buy list\n","    # Plot model importance heat map by date\n","\n","from matplotlib.pyplot import MultipleLocator\n","\n","from Model_Selection_XGBoost import *\n","\n","\n","# Function to plot the model importance heat map by date\n","def plot_importance_bydate(importance_list, x_axis, y_axis, save_path=None, font_size=12.5):\n","    x_axis, importance_list = x_axis[::3], importance_list[::3]\n","    importance_list = np.array(importance_list).T\n","    if len(importance_list) == 1: importance_list = importance_list.reshape(importance_list.shape[1], 1)\n","    df = pd.DataFrame(importance_list, index=y_axis, columns=x_axis)\n","    df = df.reindex(df.sum(axis=1).sort_values(ascending=False).index, axis=0)\n","\n","    f, ax = plt.subplots(figsize=(20, 18))\n","    heatmap = sns.heatmap(data=df, cmap=plt.cm.Blues)\n","\n","    cax = plt.gcf().axes[-1]\n","    cax.tick_params(labelsize=font_size * 1.5)\n","\n","    plt.xticks(fontsize=font_size, rotation=50)\n","    plt.yticks(fontsize=font_size)\n","\n","    plt.xlabel('date', fontsize=font_size * 1.5)\n","    plt.ylabel('factors', fontsize=font_size * 1.5)\n","\n","    if save_path != None:\n","        plt.savefig(save_path + '.png')\n","\n","    plt.show()\n","\n","\n","if __name__ == '__main__':\n","    start_time_total = time.time()\n","    pro = authorization_jq(1)\n","\n","    drop=True\n","    interval = 20\n","    start_date = '2007-01-01'\n","    end_date = '2020-07-15'\n","    base_date = '2015-12-31'\n","    date_list = get_date_list(start_date, end_date, base_date, interval=interval)\n","    date_list_selected = list_slice(date_list, '2010-01-25', '2020-06-10')\n","    acc_list = read_from_file('acc', 'Database/result')\n","    print(np.mean(acc_list))\n","\n","    year = 1\n","    acc_list = []\n","    buy_list = {}\n","    importance_list = []\n","\n","    for current_date in date_list_selected:\n","        # for current_date in date_list_selected[::-1]:\n","        start_time = time.time()\n","        print(current_date)\n","\n","        # Retrieve and split the training set and test set\n","        training_set, test_set = get_dataset_bydate(current_date, date_list, interval=interval, year=year,drop=drop)\n","        X_train, Y_train = xy_split(training_set)\n","        X_test, Y_test = xy_split(test_set)\n","\n","        # Retrieve the best model of current date from saved file\n","        grid_search_model = read_from_file('model' + '_' + current_date + '_' + str(year), 'Database/result/model')[0]\n","        model = grid_search_model.best_estimator_\n","        # model=model_ungpu(model)\n","\n","        score, Y_prob, model = get_model_auc(model, X_train, Y_train, X_test, Y_test, acc=True, prob=True, fit=True)\n","\n","        # Acquire the feature importance sorted list\n","        importance=model.get_booster().get_score(importance_type=\"gain\")\n","        importance=[importance.get(f) for f in model.get_booster().feature_names]\n","        importance=np.array(importance)\n","        importance=importance/importance.sum()\n","        importance_list.append(importance)\n","        #importance_list.append(model.feature_importances_)\n","        x_axis = [x[2:] for x in date_list_selected[:date_list_selected.index(current_date) + 1]]\n","        y_axis = X_train.columns.values.tolist()\n","\n","        acc_list.append(score * 100.0)\n","\n","        # Take the top N stocks predicted as positive probability to form the buy list\n","        score, Y_pre, model = get_model_auc(model, X_train, Y_train, X_test, Y_test, acc=True, fit=False)\n","        Y_prob = pd.DataFrame(np.hstack((Y_prob, Y_test.as_matrix().reshape(len(Y_test), 1))), index=X_test.index)\n","        Y_prob.sort_values(by=[1], ascending=False, inplace=True)\n","        buy_list.update({current_date: [list(Y_prob.index)[:20], list(Y_prob.index)[:50], list(Y_prob.index)[:100]]})\n","\n","    # Plot model accuracy figure by date\n","    save_to_file(acc_list, 'acc', 'Database/result')\n","    x_axis = [x[2:] for x in date_list_selected]\n","    plot_one_dim_50(x_axis, [acc_list], ['test set'], 'date', 'acc', save_path='Database/result/acc')\n","    # Save buy list\n","    import json\n","    jsObj = json.dumps(buy_list)\n","    fileObject = open('Database/result/buy_list.json', 'w')\n","    fileObject.write(jsObj)\n","    fileObject.close()\n","    # Plot model importance heat map by date\n","    plot_importance_bydate(importance_list, x_axis, y_axis, save_path='Database/result/importance_bydate')"],"execution_count":null,"outputs":[]}]}